{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Sentences:\n",
      "['Artificial intelligence and machine learning are shaping the future of technology.', 'These technologies help automate tasks, improve efficiency, and create innovative solutions in various fields.', 'For instance, recommendation systems and virtual assistants rely on these technologies to deliver personalized experiences.']\n",
      "\n",
      "Stemming Example:\n",
      "  Original Word Stemmed Word\n",
      "0   programming      program\n",
      "1    programmer     programm\n",
      "2    programmed      program\n",
      "3      programs      program\n",
      "4  programmatic   programmat\n",
      "\n",
      "Lemmatization Example:\n",
      "  Original Word Lemmatized Word\n",
      "0       running             run\n",
      "1          runs             run\n",
      "2           ran             run\n",
      "3        easily          easily\n",
      "4        better          better\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "mytext = \"\"\"Artificial intelligence and machine learning are shaping the future of technology. \n",
    "These technologies help automate tasks, improve efficiency, and create innovative solutions in various fields. \n",
    "For instance, recommendation systems and virtual assistants rely on these technologies to deliver personalized experiences.\"\"\"\n",
    "\n",
    "my_sentences = sent_tokenize(mytext)\n",
    "print(\"Tokenized Sentences:\")\n",
    "print(my_sentences)\n",
    "\n",
    "print(\"\\nStemming Example:\")\n",
    "porter_stemmer = PorterStemmer()\n",
    "words_to_stem = [\"programming\", \"programmer\", \"programmed\", \"programs\", \"programmatic\"]\n",
    "stemmed_words = [porter_stemmer.stem(word=word) for word in words_to_stem]\n",
    "stem_df = pd.DataFrame({'Original Word': words_to_stem, 'Stemmed Word': stemmed_words})\n",
    "print(stem_df)\n",
    "\n",
    "print(\"\\nLemmatization Example:\")\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "words_to_lemmatize = [\"running\", \"runs\", \"ran\", \"easily\", \"better\"]\n",
    "lemmatized_words = [lemmatizer.lemmatize(word=word, pos='v') for word in words_to_lemmatize]\n",
    "lemmatized_df = pd.DataFrame({'Original Word': words_to_lemmatize, 'Lemmatized Word': lemmatized_words})\n",
    "print(lemmatized_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
