{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Sentences:\n",
      "['Artificial intelligence and machine learning are shaping the future of technology.', 'These technologies help automate tasks, improve efficiency, and create innovative solutions in various fields.', 'For instance, recommendation systems and virtual assistants rely on these technologies to deliver personalized experiences.']\n",
      "\n",
      "Stemming Example:\n",
      "                                         Original Word Stemmed Word\n",
      "0    Artificial intelligence and machine learning a...            a\n",
      "1    Artificial intelligence and machine learning a...            r\n",
      "2    Artificial intelligence and machine learning a...            t\n",
      "3    Artificial intelligence and machine learning a...            i\n",
      "4    Artificial intelligence and machine learning a...            f\n",
      "..                                                 ...          ...\n",
      "314  Artificial intelligence and machine learning a...            n\n",
      "315  Artificial intelligence and machine learning a...            c\n",
      "316  Artificial intelligence and machine learning a...            e\n",
      "317  Artificial intelligence and machine learning a...            s\n",
      "318  Artificial intelligence and machine learning a...            .\n",
      "\n",
      "[319 rows x 2 columns]\n",
      "\n",
      "Lemmatization Example:\n",
      "                                         Original Word Lemmatized Word\n",
      "0    Artificial intelligence and machine learning a...               A\n",
      "1    Artificial intelligence and machine learning a...               r\n",
      "2    Artificial intelligence and machine learning a...               t\n",
      "3    Artificial intelligence and machine learning a...               i\n",
      "4    Artificial intelligence and machine learning a...               f\n",
      "..                                                 ...             ...\n",
      "314  Artificial intelligence and machine learning a...               n\n",
      "315  Artificial intelligence and machine learning a...               c\n",
      "316  Artificial intelligence and machine learning a...               e\n",
      "317  Artificial intelligence and machine learning a...               s\n",
      "318  Artificial intelligence and machine learning a...               .\n",
      "\n",
      "[319 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "mytext = \"\"\"Artificial intelligence and machine learning are shaping the future of technology. \n",
    "These technologies help automate tasks, improve efficiency, and create innovative solutions in various fields. \n",
    "For instance, recommendation systems and virtual assistants rely on these technologies to deliver personalized experiences.\"\"\"\n",
    "\n",
    "my_sentences = sent_tokenize(mytext)\n",
    "print(\"Tokenized Sentences:\")\n",
    "print(my_sentences)\n",
    "\n",
    "print(\"\\nStemming Example:\")\n",
    "porter_stemmer = PorterStemmer()\n",
    "#words_to_stem = [\"programming\", \"programmer\", \"programmed\", \"programs\", \"programmatic\"]\n",
    "stemmed_words = [porter_stemmer.stem(word=word) for word in mytext]\n",
    "stem_df = pd.DataFrame({'Original Word': mytext, 'Stemmed Word': stemmed_words})\n",
    "print(stem_df)\n",
    "\n",
    "print(\"\\nLemmatization Example:\")\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "#words_to_lemmatize = [\"running\", \"runs\", \"ran\", \"easily\", \"better\"]\n",
    "lemmatized_words = [lemmatizer.lemmatize(word=word, pos='v') for word in mytext]\n",
    "lemmatized_df = pd.DataFrame({'Original Word': mytext, 'Lemmatized Word': lemmatized_words})\n",
    "print(lemmatized_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
